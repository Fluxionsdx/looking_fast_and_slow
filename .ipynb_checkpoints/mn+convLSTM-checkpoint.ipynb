{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 3)\n",
      "(None, None, None, 3)\n",
      "(None, None, None, 32)\n",
      "(None, None, None, 32)\n",
      "(None, None, None, 32)\n",
      "(None, None, None, 32)\n",
      "(None, None, None, 32)\n",
      "(None, None, None, 32)\n",
      "(None, None, None, 64)\n",
      "(None, None, None, 64)\n",
      "(None, None, None, 64)\n",
      "(None, None, None, 64)\n",
      "(None, None, None, 64)\n",
      "(None, None, None, 64)\n",
      "(None, None, None, 64)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 1024)\n"
     ]
    }
   ],
   "source": [
    "mn = tf.keras.applications.mobilenet.MobileNet(include_top=False, weights='imagenet')\n",
    "inputs = layers.Input((224,224,3))\n",
    "mobilenet = tf.keras.applications.mobilenet.MobileNet(include_top=False, weights='imagenet')\n",
    "nt = mobilenet(inputs)\n",
    "\n",
    "mdl = Model(inputs, nt)\n",
    "\n",
    "for layer in mobilenet.layers:\n",
    "    print(layer.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        (None, None, 224, 224, 3) 0         \n",
      "_________________________________________________________________\n",
      "mn (TimeDistributed)         (None, None, 7, 7, 1024)  3228864   \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_7 (ConvLSTM2D)  (None, 5, 5, 50)          1933400   \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 5, 250)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 5, 2)              502       \n",
      "=================================================================\n",
      "Total params: 5,162,766\n",
      "Trainable params: 1,933,902\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input((None,224,224,3))\n",
    "mobilenet = tf.keras.applications.mobilenet.MobileNet(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "net = layers.TimeDistributed(mobilenet, name=\"mn\")(inputs)\n",
    "net = layers.ConvLSTM2D(50,3, return_sequences=True)(net)\n",
    "net = layers.TimeDistributed(layers.Flatten())(net)\n",
    "net = layers.TimeDistributed(layers.Dense(2, activation=\"softmax\"))(net)\n",
    "model = Model(inputs,net)\n",
    "\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_example(example):\n",
    "    # need to modify this function to have variable number of timesteps\n",
    "    example[\"image\"] = tf.image.resize(example[\"image\"], (224,224))\n",
    "    example[\"image\"] = tf.stack([example[\"image\"], example[\"image\"], example[\"image\"]])\n",
    "    \n",
    "    example[\"label\"] = tf.stack([example[\"label\"],example[\"label\"],example[\"label\"]])\n",
    "    \n",
    "    data = example[\"image\"]\n",
    "    label = example[\"label\"]\n",
    "\n",
    "    return data, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    ds_train = tfds.load(name=\"cats_vs_dogs\", split=tfds.Split.TRAIN.subsplit(tfds.percent[:90]))\n",
    "    ds_train = ds_train.map(load_example).repeat().batch(16)\n",
    "    #ds_train = ds_train.batch(16)\n",
    "    #ds_train = ds_train.repeat()\n",
    "\n",
    "    ds_test = tfds.load(name=\"cats_vs_dogs\", split=tfds.Split.TRAIN.subsplit(tfds.percent[91:]))\n",
    "    ds_test = ds_test.map(load_example)\n",
    "    ds_test = ds_test.batch(16)\n",
    "    ds_test = ds_test.repeat()\n",
    "    \n",
    "    \n",
    "    return ds_train, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test = create_datasets()\n",
    "#for example in ds_train.take(1):\n",
    "#    print(example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0625 14:11:28.704260 140736281645952 deprecation.py:323] From /anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [16,3] vs. [16,5,2]\n\t [[{{node metrics_3/acc/Equal}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c15c0af1642a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1309\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m131\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m           \u001b[0;31m# `ins` can be callable in DistributionStrategy + eager case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           logging.warning('Your dataset iterator ran out of data; '\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [16,3] vs. [16,5,2]\n\t [[{{node metrics_3/acc/Equal}}]]"
     ]
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=3, steps_per_epoch=1309 ,validation_data=ds_test, validation_steps=131)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl] *",
   "language": "python",
   "name": "conda-env-dl-py-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
